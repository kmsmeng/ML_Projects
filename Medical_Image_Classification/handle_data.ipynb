{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91f5d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from pydicom import dcmread\n",
    "from PIL import Image\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693d4c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Images: 26684\n",
      "Test Data Images: 3000\n"
     ]
    }
   ],
   "source": [
    "# Get all the train data samples and test data samples path as list\n",
    "\n",
    "data_file = Path('data/pneumonia_dataset')\n",
    "\n",
    "train_path = list(data_file.glob('stage_2_train_images/*.dcm'))\n",
    "test_path = list(data_file.glob('stage_2_test_images/*.dcm'))\n",
    "print(f'Train Data Images: {len(train_path)}')\n",
    "print(f'Test Data Images: {len(test_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12af7f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO Train Data Samples: 20000\n",
      "YOLO val Data Samples: 6684\n"
     ]
    }
   ],
   "source": [
    "# Split the total data of 26684 into train and val dataset for YOLOv8\n",
    "train_size = 20000\n",
    "\n",
    "\n",
    "yolo_train_path = train_path[0: 20000]\n",
    "val_path = train_path[20000:]\n",
    "\n",
    "print(f'YOLO Train Data Samples: {len(yolo_train_path)}')\n",
    "print(f'YOLO val Data Samples: {len(val_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53678393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8</td>\n",
       "      <td>185.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>c1edf42b-5958-47ff-a1e7-4f23d99583ba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30224</th>\n",
       "      <td>c1f6b555-2eb1-4231-98f6-50a963976431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30225</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30226</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>233.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30227 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "0      0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN   \n",
       "1      00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN   \n",
       "2      00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN   \n",
       "3      003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN   \n",
       "4      00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0   \n",
       "...                                     ...    ...    ...    ...     ...   \n",
       "30222  c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8  185.0  298.0  228.0   379.0   \n",
       "30223  c1edf42b-5958-47ff-a1e7-4f23d99583ba    NaN    NaN    NaN     NaN   \n",
       "30224  c1f6b555-2eb1-4231-98f6-50a963976431    NaN    NaN    NaN     NaN   \n",
       "30225  c1f7889a-9ea9-4acb-b64c-b737c929599a  570.0  393.0  261.0   345.0   \n",
       "30226  c1f7889a-9ea9-4acb-b64c-b737c929599a  233.0  424.0  201.0   356.0   \n",
       "\n",
       "       Target  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "30222       1  \n",
       "30223       0  \n",
       "30224       0  \n",
       "30225       1  \n",
       "30226       1  \n",
       "\n",
       "[30227 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File path of the labels from the working data and convert the csv file into a pandas DataFrame\n",
    "\n",
    "label_file_path = 'data/pneumonia_dataset/stage_2_train_labels.csv'\n",
    "label_csv = pd.read_csv(label_file_path)\n",
    "label_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "371680e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of Data samples with pneumonia and without pneumonia\n",
    "\n",
    "counts = label_csv.drop_duplicates('patientId')['Target'].value_counts()\n",
    "\n",
    "# num_no_pneumonia = counts[0]\n",
    "# num_pneumonia = counts[1]\n",
    "\n",
    "data_class = {\n",
    "    'no pneumonia': int(counts.get(0, 0)),\n",
    "    'pneumonia': int(counts.get(1, 0))\n",
    "}\n",
    "\n",
    "total = sum(data_class.values())\n",
    "\n",
    "\n",
    "bars = plt.bar(data_class.keys(), data_class.values(), color=['cadetblue', 'salmon'])\n",
    "plt.bar_label(bars, labels=[f\"{value}\\n({value/total*100:.1f}%)\" for value in data_class.values()])\n",
    "plt.ylim(0, 1.2*max(data_class.values()))\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Pneumonia Dataset Class Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d3cbf7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset.file_meta -------------------------------\n",
       "(0002,0000) File Meta Information Group Length  UL: 202\n",
       "(0002,0001) File Meta Information Version       OB: b'\\x00\\x01'\n",
       "(0002,0002) Media Storage SOP Class UID         UI: Secondary Capture Image Storage\n",
       "(0002,0003) Media Storage SOP Instance UID      UI: 1.2.276.0.7230010.3.1.4.8323329.28530.1517874485.775526\n",
       "(0002,0010) Transfer Syntax UID                 UI: JPEG Baseline (Process 1)\n",
       "(0002,0012) Implementation Class UID            UI: 1.2.276.0.7230010.3.0.3.6.0\n",
       "(0002,0013) Implementation Version Name         SH: 'OFFIS_DCMTK_360'\n",
       "-------------------------------------------------\n",
       "(0008,0005) Specific Character Set              CS: 'ISO_IR 100'\n",
       "(0008,0016) SOP Class UID                       UI: Secondary Capture Image Storage\n",
       "(0008,0018) SOP Instance UID                    UI: 1.2.276.0.7230010.3.1.4.8323329.28530.1517874485.775526\n",
       "(0008,0020) Study Date                          DA: '19010101'\n",
       "(0008,0030) Study Time                          TM: '000000.00'\n",
       "(0008,0050) Accession Number                    SH: ''\n",
       "(0008,0060) Modality                            CS: 'CR'\n",
       "(0008,0064) Conversion Type                     CS: 'WSD'\n",
       "(0008,0090) Referring Physician's Name          PN: ''\n",
       "(0008,103E) Series Description                  LO: 'view: PA'\n",
       "(0010,0010) Patient's Name                      PN: '0004cfab-14fd-4e49-80ba-63a80b6bddd6'\n",
       "(0010,0020) Patient ID                          LO: '0004cfab-14fd-4e49-80ba-63a80b6bddd6'\n",
       "(0010,0030) Patient's Birth Date                DA: ''\n",
       "(0010,0040) Patient's Sex                       CS: 'F'\n",
       "(0010,1010) Patient's Age                       AS: '51'\n",
       "(0018,0015) Body Part Examined                  CS: 'CHEST'\n",
       "(0018,5101) View Position                       CS: 'PA'\n",
       "(0020,000D) Study Instance UID                  UI: 1.2.276.0.7230010.3.1.2.8323329.28530.1517874485.775525\n",
       "(0020,000E) Series Instance UID                 UI: 1.2.276.0.7230010.3.1.3.8323329.28530.1517874485.775524\n",
       "(0020,0010) Study ID                            SH: ''\n",
       "(0020,0011) Series Number                       IS: '1'\n",
       "(0020,0013) Instance Number                     IS: '1'\n",
       "(0020,0020) Patient Orientation                 CS: ''\n",
       "(0028,0002) Samples per Pixel                   US: 1\n",
       "(0028,0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
       "(0028,0010) Rows                                US: 1024\n",
       "(0028,0011) Columns                             US: 1024\n",
       "(0028,0030) Pixel Spacing                       DS: [0.14300000000000002, 0.14300000000000002]\n",
       "(0028,0100) Bits Allocated                      US: 8\n",
       "(0028,0101) Bits Stored                         US: 8\n",
       "(0028,0102) High Bit                            US: 7\n",
       "(0028,0103) Pixel Representation                US: 0\n",
       "(0028,2110) Lossy Image Compression             CS: '01'\n",
       "(0028,2114) Lossy Image Compression Method      CS: 'ISO_10918_1'\n",
       "(7FE0,0010) Pixel Data                          OB: Array of 142006 elements"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if neumonia cases vary by metadata like (age, sex, image view)\n",
    "\n",
    "data = dcmread(train_path[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b262f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm_to_jpg(dcm_path, save_path):\n",
    "    '''\n",
    "    Convert a DICOM (.dcm) file to a JPEG (.jpg) file and save it.\n",
    "\n",
    "    This function reads a DICOM file from `dcm_path`, converts the pixel data\n",
    "    to an image, and saves the image as a JPEG file at `save_path`.\n",
    "\n",
    "    Args:\n",
    "        dcm_path (str): File path of the input DICOM file.\n",
    "        save_path (str): File path to save the output JPEG file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    save_path = Path(save_path)\n",
    "\n",
    "    if not save_path.is_dir():\n",
    "        dcm_data = dcmread(dcm_path)\n",
    "        dcm_pixel_array = dcm_data.pixel_array\n",
    "        image = Image.fromarray(dcm_pixel_array)\n",
    "        image.save(save_path, 'JPEG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ec1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLO File format list\n",
    "\n",
    "yolo_file_format = ['YOLO_format_data', ['images', 'labels', 'data.yaml'], ['train', 'val']]\n",
    "\n",
    "# Create the YOLO file format directory\n",
    "for x in range(2):\n",
    "    for y in range(2):\n",
    "        form_path = os.path.join(yolo_file_format[0], yolo_file_format[1][x], yolo_file_format[2][y])\n",
    "        form_path = Path(form_path)\n",
    "        form_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Create data.yaml file\n",
    "yaml_file = Path(yolo_file_format[0]) / yolo_file_format[1][2]\n",
    "\n",
    "# Content for the data.yaml file as required by the YOLO model\n",
    "yaml_content = {\n",
    "    'train': f'{yolo_file_format[1][0]}/{yolo_file_format[2][0]}',\n",
    "    'val': f'{yolo_file_format[1][0]}/{yolo_file_format[2][1]}',\n",
    "    'nc': 1,\n",
    "    'names': ['pneumonia']\n",
    "}\n",
    "\n",
    "# write the content into the data.yaml file\n",
    "with open(yaml_file, 'w') as file:\n",
    "    yaml.dump(yaml_content, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8393f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the training images into the images direcotry\n",
    "\n",
    "train_image_name_list = []\n",
    "for x in range(len(yolo_train_path)):\n",
    "    img = f'img{x+1}.jpg'\n",
    "    train_image_name_list.append(img)\n",
    "\n",
    "train_yolo_img = Path('YOLO_format_data/images/train')\n",
    "\n",
    "\n",
    "\n",
    "for index, path in enumerate(yolo_train_path):\n",
    "    save_path = os.path.join(train_yolo_img, train_image_name_list[index])\n",
    "    dcm_to_jpg(dcm_path=path, save_path=save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c74b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the val images into the val directory\n",
    "\n",
    "val_image_name_list = []\n",
    "cont = len(train_image_name_list)\n",
    "cont\n",
    "for x in range(len(val_path)):\n",
    "    img = f'img{cont+x+1}.jpg'\n",
    "    val_image_name_list.append(img)\n",
    "\n",
    "val_yolo_img = Path('YOLO_format_data/images/val')\n",
    "\n",
    "for index, path in enumerate(val_path):\n",
    "    save_path = os.path.join(val_yolo_img, val_image_name_list[index])\n",
    "    dcm_to_jpg(dcm_path=path, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd913384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8</td>\n",
       "      <td>185.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>c1edf42b-5958-47ff-a1e7-4f23d99583ba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30224</th>\n",
       "      <td>c1f6b555-2eb1-4231-98f6-50a963976431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30225</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30226</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>233.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30227 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "0      0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN   \n",
       "1      00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN   \n",
       "2      00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN   \n",
       "3      003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN   \n",
       "4      00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0   \n",
       "...                                     ...    ...    ...    ...     ...   \n",
       "30222  c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8  185.0  298.0  228.0   379.0   \n",
       "30223  c1edf42b-5958-47ff-a1e7-4f23d99583ba    NaN    NaN    NaN     NaN   \n",
       "30224  c1f6b555-2eb1-4231-98f6-50a963976431    NaN    NaN    NaN     NaN   \n",
       "30225  c1f7889a-9ea9-4acb-b64c-b737c929599a  570.0  393.0  261.0   345.0   \n",
       "30226  c1f7889a-9ea9-4acb-b64c-b737c929599a  233.0  424.0  201.0   356.0   \n",
       "\n",
       "       Target  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "30222       1  \n",
       "30223       0  \n",
       "30224       0  \n",
       "30225       1  \n",
       "30226       1  \n",
       "\n",
       "[30227 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File path of the labels from the working data and convert the csv file into a pandas DataFrame\n",
    "\n",
    "label_file_path = 'data/pneumonia_dataset/stage_2_train_labels.csv'\n",
    "label_csv = pd.read_csv(label_file_path)\n",
    "label_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955e2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the txt files names for train labels file\n",
    "\n",
    "train_image_txt_list = []\n",
    "\n",
    "for image_name in train_image_name_list:\n",
    "    image_name = Path(image_name)\n",
    "    name = image_name.stem\n",
    "    txt_fil_name = f'{name}.txt'\n",
    "    train_image_txt_list.append(txt_fil_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f3e96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to save the train labels file to\n",
    "labels_train = Path('YOLO_format_data/labels/train')\n",
    "\n",
    "\n",
    "# Iterate over each path from the list of training data path\n",
    "for index, path in enumerate(yolo_train_path):\n",
    "\n",
    "    # Patient Id of the instance of data \n",
    "    id = path.stem\n",
    "    # Get all the label data associated with the Id\n",
    "    bbox_data = label_csv[label_csv['patientId'] == id] \n",
    "\n",
    "    # final file path to save the instance of label data to\n",
    "    labels_train_txt = os.path.join(labels_train, train_image_txt_list[index])\n",
    "\n",
    "    # Create a  label file for each image data\n",
    "    with open(labels_train_txt, 'w') as f:\n",
    "        # write label into the file if the bbox for the image exists \n",
    "        if bbox_data.iloc[0, 5].item() == 1:\n",
    "            label_class_id = bbox_data.iloc[0, 5].item()\n",
    "            for x in range(len(bbox_data)):\n",
    "                x1 = bbox_data.iloc[x, 1].item() / 1024\n",
    "                y1 = bbox_data.iloc[x, 2].item() / 1024\n",
    "                width = bbox_data.iloc[x, 3].item() / 1024\n",
    "                height = bbox_data.iloc[x, 4].item() / 1024\n",
    "                f.write(f'{label_class_id-1} {x1} {y1} {width} {height}')\n",
    "                f.write('\\n')\n",
    "        # Write nth into the file if no bbox for the instance of data exist\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82c8ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the txt files names for val labels file\n",
    "\n",
    "val_image_txt_list = []\n",
    "\n",
    "for image_name in val_image_name_list:\n",
    "    image_name = Path(image_name)\n",
    "    name = image_name.stem\n",
    "    txt_fil_name = f'{name}.txt'\n",
    "    val_image_txt_list.append(txt_fil_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1dd4ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = Path('YOLO_format_data/labels/val')\n",
    "\n",
    "x = 0\n",
    "for index, path in enumerate(val_path):\n",
    "    id = path.stem\n",
    "    bbox_data = label_csv[label_csv['patientId'] == id]\n",
    "\n",
    "    labels_train_txt = os.path.join(labels_val, val_image_txt_list[index])\n",
    "\n",
    "    with open(labels_train_txt, 'w') as f:\n",
    "        if bbox_data.iloc[0, 5].item() == 1:\n",
    "            label_class_id = bbox_data.iloc[0, 5].item()\n",
    "            for x in range(len(bbox_data)):\n",
    "                x1 = bbox_data.iloc[x, 1].item() / 1024\n",
    "                y1 = bbox_data.iloc[x, 2].item() / 1024\n",
    "                width = bbox_data.iloc[x, 3].item() / 1024\n",
    "                height = bbox_data.iloc[x, 4].item() / 1024\n",
    "                f.write(f'{label_class_id-1} {x1} {y1} {width} {height}')\n",
    "                f.write('\\n')\n",
    "        # Write nth into the file if no bbox for the instance of data exist\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba02949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda3e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cc3fc1f",
   "metadata": {},
   "source": [
    "# Workign with the data part is done...now fine tuning the model part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28ddc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ffb981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "052ad12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = model.train(\n",
    "    data='YOLO_format_data/data.yaml',\n",
    "    epochs=5,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='medical_imaging'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df87a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "# Cheked one image of the data and it was in shape of 1024*1024 so a loop to check if all the image are also in 1024*1024 or not\n",
    "\n",
    "# len(yolo_train_path)\n",
    "# x = dcmread(yolo_train_path[3])\n",
    "# shape = x.pixel_array.shape\n",
    "# for x in shape:\n",
    "#     print(x)\n",
    "\n",
    "\n",
    "# for index, path in enumerate(yolo_train_path):\n",
    "#     data = dcmread(path)\n",
    "#     image_shape = data.pixel_array.shape\n",
    "#     for x in image_shape:\n",
    "#         if x != 1024:\n",
    "#             print(index)\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2c355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6ebfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc277279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.152 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.145  Python-3.13.1 torch-2.6.0+cu126 CUDA:0 (NVIDIA T400 4GB, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=YOLO_format_data/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=runs\\detect\\medical_imaging_50_epo\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=medical_imaging_50_epo, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=runs\\detect\\medical_imaging_50_epo\\weights\\last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\medical_imaging_50_epo, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA T400 4GB GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 210.8103.9 MB/s, size: 59.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\w10195102\\Desktop\\PROJECTS\\ML_Projects\\Medical_Image_Classification\\YOLO_format_data\\labels\\train.cache... 20000 images, 14917 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 232.0118.7 MB/s, size: 57.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\w10195102\\Desktop\\PROJECTS\\ML_Projects\\Medical_Image_Classification\\YOLO_format_data\\labels\\val.cache... 6684 images, 5755 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6684/6684 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\medical_imaging_50_epo\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Resuming training runs\\detect\\medical_imaging_50_epo\\weights\\last.pt from epoch 15 to 50 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\medical_imaging_50_epo\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      3.81G      1.714       2.46      1.794         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [20:40<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [02:58<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.319      0.278      0.216     0.0745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      3.84G       1.69      2.402      1.778         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [21:15<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [03:08<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.317      0.263      0.216     0.0776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      3.84G      1.679      2.394       1.77         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [20:50<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [03:06<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.306      0.328      0.252     0.0896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      3.84G        1.7       2.42      1.787          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [20:33<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [03:07<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.322      0.314       0.26     0.0917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      3.84G      1.695      2.408      1.782          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [20:51<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [03:07<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.316      0.297      0.235     0.0861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      3.84G      1.721      2.442      1.801          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [20:49<00:00,  1.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [03:07<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.311      0.303      0.237     0.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      3.84G      1.754      2.503      1.814         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [21:00<00:00,  1.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [02:56<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.359      0.307      0.263     0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      3.84G      1.764      2.516      1.832          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [20:53<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [03:08<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.331      0.272      0.235     0.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      3.84G      1.781      2.549      1.836         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [20:35<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209/209 [02:58<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6684       1359      0.292      0.302      0.238      0.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      3.84G      1.762      2.353      1.822         13        640:   6%|â–Œ         | 71/1250 [01:09<19:17,  1.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# # Instanciate a new training \u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# model = YOLO('runs/detect/medical_imaging_v4/weights/best.pt')\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# model.train(data='YOLO_format_data/data.yaml', epochs=50, project='runs/detect', name='medical_imaging_50_epo')\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Continue Training\u001b[39;00m\n\u001b[32m      9\u001b[39m model = YOLO(\u001b[33m'\u001b[39m\u001b[33mruns/detect/medical_imaging_50_epo/weights/last.pt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\w10195102\\Desktop\\PROJECTS\\ML_Projects\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:797\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    796\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\w10195102\\Desktop\\PROJECTS\\ML_Projects\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\w10195102\\Desktop\\PROJECTS\\ML_Projects\\.venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:435\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n\u001b[32m    434\u001b[39m     loss_length = \u001b[38;5;28mself\u001b[39m.tloss.shape[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.tloss.shape) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[43mpbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_description\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%11s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%11.4g\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.3g\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43mG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (GB) GPU memory util\u001b[39;49;00m\n\u001b[32m    440\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloss_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# losses\u001b[39;49;00m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# batch size, i.e. 8\u001b[39;49;00m\n\u001b[32m    442\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# imgsz, i.e 640\u001b[39;49;00m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m     \u001b[38;5;28mself\u001b[39m.run_callbacks(\u001b[33m\"\u001b[39m\u001b[33mon_batch_end\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.plots \u001b[38;5;129;01mand\u001b[39;00m ni \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.plot_idx:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\w10195102\\Desktop\\PROJECTS\\ML_Projects\\.venv\\Lib\\site-packages\\tqdm\\std.py:1382\u001b[39m, in \u001b[36mtqdm.set_description\u001b[39m\u001b[34m(self, desc, refresh)\u001b[39m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_miniters = EMA(\u001b[38;5;28mself\u001b[39m.smoothing)\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28mself\u001b[39m.refresh()\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_description\u001b[39m(\u001b[38;5;28mself\u001b[39m, desc=\u001b[38;5;28;01mNone\u001b[39;00m, refresh=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1383\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1384\u001b[39m \u001b[33;03m    Set/modify description of the progress bar.\u001b[39;00m\n\u001b[32m   1385\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1390\u001b[39m \u001b[33;03m        Forces refresh [default: True].\u001b[39;00m\n\u001b[32m   1391\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1392\u001b[39m     \u001b[38;5;28mself\u001b[39m.desc = desc + \u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m desc \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# # Instanciate a new training \n",
    "# model = YOLO('runs/detect/medical_imaging_v4/weights/best.pt')\n",
    "# model.train(data='YOLO_format_data/data.yaml', epochs=50, project='runs/detect', name='medical_imaging_50_epo')\n",
    "\n",
    "\n",
    "# Continue Training\n",
    "model = YOLO('runs/detect/medical_imaging_50_epo/weights/last.pt')\n",
    "model.train(resume=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
